{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Environment configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: DeepSaki==0.1.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 1)) (0.1.3)\n",
      "Requirement already satisfied: keras==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: tensorboard==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 3)) (2.10.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.6.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: tensorflow==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 6)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-addons==0.19.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 7)) (0.19.0)\n",
      "Requirement already satisfied: tensorflow-estimator==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 8)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 9)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.29.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 10)) (0.29.0)\n",
      "Requirement already satisfied: pydantic==1.10.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 11)) (1.10.4)\n",
      "Requirement already satisfied: pymongo==4.3.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 12)) (4.3.3)\n",
      "Requirement already satisfied: pandas in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from DeepSaki==0.1.3->-r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: numpy in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from DeepSaki==0.1.3->-r requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.28.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (1.51.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (3.19.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (65.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: packaging in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (23.1.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (15.0.6.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (3.7.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow-addons==0.19.0->-r requirements.txt (line 7)) (2.13.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pymongo==4.3.3->-r requirements.txt (line 12)) (2.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (5.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from markdown>=2.6.8->tensorboard==2.10.0->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pandas->DeepSaki==0.1.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pandas->DeepSaki==0.1.3->-r requirements.txt (line 1)) (2022.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Upgrading pip which will be used to install all libraries\n",
    "!pip install -r requirements.txt\n",
    "# !pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on single GPU  /device:GPU:0\n",
      "Number of accelerators:  1\n",
      "____________________________________________________________________________________\n",
      "Device List: \n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9027242169430391422\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1721342363\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17701183863651686981\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# to check if working on GPU\n",
    "# !pip install DeepSaki\n",
    "from tensorflow import keras\n",
    "import DeepSaki\n",
    "strategy, RUNTIME_ENVIRONMENT, hw_accelerator_handle = DeepSaki.utils.DetectHw()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Content-based filtering using TF-IDF score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "# from ../models/msd_song import MsdSongWithLyrics\n",
    "from models.msd_song import MsdSongWithLyrics\n",
    "from dao.dao_msd_songs_with_lyrics import DAOMsdSongsWithLyrics\n",
    "\n",
    "dao_songs_with_lyrics: DAOMsdSongsWithLyrics = DAOMsdSongsWithLyrics()\n",
    "songs: List[MsdSongWithLyrics] = dao_songs_with_lyrics.find_many_by_query({'lyrics': {'$ne':None}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "              song_id               title  \\\n0  SOLJTLX12AB01890ED  El hijo del pueblo   \n1  SOMPVQB12A8C1379BB              Pilots   \n2  SOSDCFG12AB0184647                 006   \n3  SOKOVRQ12A8C142811   Ethos of Coercion   \n4  SOIMMJJ12AF72AD643         Rock-N-Rule   \n\n                                release      artist_name  year ratings_amount  \\\n0               32 Grandes Éxitos  CD 2    Jorge Negrete  1997           None   \n1                             The Loyal        Tiger Lou  2005           None   \n2                            Lena 20 År  Lena Philipsson  1998           None   \n3                Descend Into Depravity      Dying Fetus  2009           None   \n4  I'm Only A Man (Bonus Track Version)            Emery  2007           None   \n\n    tag features                                             lyrics  \n0   pop       []  Es mi orgullo haber nacido en el barrio más hu...  \n1   pop       []  Raise the chandelier light the candels dear i ...  \n2   pop       []  I had come in the name of love\\nWith a mission...  \n3  rock       []  Castigation of the offenders, no punishment ou...  \n4  rock       []  [Intro]\\nThis is a waking up\\nThis is your fin...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>title</th>\n      <th>release</th>\n      <th>artist_name</th>\n      <th>year</th>\n      <th>ratings_amount</th>\n      <th>tag</th>\n      <th>features</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SOLJTLX12AB01890ED</td>\n      <td>El hijo del pueblo</td>\n      <td>32 Grandes Éxitos  CD 2</td>\n      <td>Jorge Negrete</td>\n      <td>1997</td>\n      <td>None</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>Es mi orgullo haber nacido en el barrio más hu...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SOMPVQB12A8C1379BB</td>\n      <td>Pilots</td>\n      <td>The Loyal</td>\n      <td>Tiger Lou</td>\n      <td>2005</td>\n      <td>None</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>Raise the chandelier light the candels dear i ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SOSDCFG12AB0184647</td>\n      <td>006</td>\n      <td>Lena 20 År</td>\n      <td>Lena Philipsson</td>\n      <td>1998</td>\n      <td>None</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>I had come in the name of love\\nWith a mission...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SOKOVRQ12A8C142811</td>\n      <td>Ethos of Coercion</td>\n      <td>Descend Into Depravity</td>\n      <td>Dying Fetus</td>\n      <td>2009</td>\n      <td>None</td>\n      <td>rock</td>\n      <td>[]</td>\n      <td>Castigation of the offenders, no punishment ou...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SOIMMJJ12AF72AD643</td>\n      <td>Rock-N-Rule</td>\n      <td>I'm Only A Man (Bonus Track Version)</td>\n      <td>Emery</td>\n      <td>2007</td>\n      <td>None</td>\n      <td>rock</td>\n      <td>[]</td>\n      <td>[Intro]\\nThis is a waking up\\nThis is your fin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = songs[0].dict().keys()\n",
    "songs_values = [song.dict().values() for song in songs]\n",
    "songs_df = pd.DataFrame(songs_values, columns=headers)\n",
    "songs_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dao_songs: DAOMsdSongsWithLyrics = DAOMsdSongsWithLyrics()\n",
    "songs_without: List[MsdSongWithLyrics] = dao_songs.find_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "              song_id              title  \\\n0  SOQMMHC12AB0180CB8       Silent Night   \n1  SOVFVAK12A8C1350D9        Tanssi vaan   \n2  SOGTUKN12AB017F4F1  No One Could Ever   \n3  SOBNYVR12A8C13558C      Si Vos Querés   \n4  SOHSBXH12A8C13B0DF   Tangle Of Aspens   \n\n                                release       artist_name  year  \\\n0                 Monster Ballads X-Mas  Faster Pussy cat  2003   \n1                           Karkuteillä  Karkkiautomaatti  1995   \n2                                Butter    Hudson Mohawke  2006   \n3                               De Culo       Yerba Brava  2003   \n4  Rene Ablaze Presents Winter Sessions        Der Mystic     0   \n\n  ratings_amount   tag features lyrics  \n0           None  None     None   None  \n1           None  None     None   None  \n2           None  None     None   None  \n3           None  None     None   None  \n4           None  None     None   None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>title</th>\n      <th>release</th>\n      <th>artist_name</th>\n      <th>year</th>\n      <th>ratings_amount</th>\n      <th>tag</th>\n      <th>features</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SOQMMHC12AB0180CB8</td>\n      <td>Silent Night</td>\n      <td>Monster Ballads X-Mas</td>\n      <td>Faster Pussy cat</td>\n      <td>2003</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SOVFVAK12A8C1350D9</td>\n      <td>Tanssi vaan</td>\n      <td>Karkuteillä</td>\n      <td>Karkkiautomaatti</td>\n      <td>1995</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SOGTUKN12AB017F4F1</td>\n      <td>No One Could Ever</td>\n      <td>Butter</td>\n      <td>Hudson Mohawke</td>\n      <td>2006</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SOBNYVR12A8C13558C</td>\n      <td>Si Vos Querés</td>\n      <td>De Culo</td>\n      <td>Yerba Brava</td>\n      <td>2003</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SOHSBXH12A8C13B0DF</td>\n      <td>Tangle Of Aspens</td>\n      <td>Rene Ablaze Presents Winter Sessions</td>\n      <td>Der Mystic</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = songs[0].dict().keys()\n",
    "songs_values = [song.dict().values() for song in songs_without]\n",
    "songs_without_df = pd.DataFrame(songs_values, columns=headers)\n",
    "songs_without_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181334\n",
      "1000000\n",
      "181334\n"
     ]
    }
   ],
   "source": [
    "print(len(songs_df))\n",
    "print(len(songs_without_df))\n",
    "songs_without_df.dropna(subset='lyrics', inplace=True)\n",
    "print(len(songs_without_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ewakae\\AppData\\Local\\Temp\\ipykernel_1236\\2959928106.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  songs_df['lyrics'] = songs_df['lyrics'].str.replace(r'\\n', ' ')\n"
     ]
    }
   ],
   "source": [
    "songs_df['lyrics'] = songs_df['lyrics'].str.replace(r'\\n', ' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0         Es mi orgullo haber nacido en el barrio más hu...\n1         Raise the chandelier light the candels dear i ...\n2         I had come in the name of love With a mission ...\n3         Castigation of the offenders, no punishment ou...\n4         [Intro] This is a waking up This is your final...\n                                ...                        \n181329    Yesterday I went outside And all my grass had ...\n181330    Big girls like telling boys that shove \"fact i...\n181331    [Verse 1] Think of me as your soldier The man ...\n181332    Interrotte speranze, eterna fede Fiamme e stra...\n181333    Where do you go with all of those scars They r...\nName: lyrics, Length: 181334, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df['lyrics']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: colorama in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ewakae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "final_stopwords_list = stopwords.words('english') + stopwords.words('french') + stopwords.words('spanish') + stopwords.words('swedish')\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words=final_stopwords_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "songs_df = songs_df[:20000]\n",
    "tfidf_matrix = tfidf.fit_transform(songs_df['lyrics'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<20000x106683 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1170789 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(20000, 106683)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Content-based recommendation based on sigmoid kernel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "\n",
    "songs_sig = sigmoid_kernel(tfidf_matrix, tfidf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.76159809, 0.76159416, 0.76159416, ..., 0.76159416, 0.76159416,\n        0.76159432],\n       [0.76159416, 0.76159809, 0.76159416, ..., 0.76159416, 0.76159416,\n        0.76159416],\n       [0.76159416, 0.76159416, 0.76159809, ..., 0.7615942 , 0.76159416,\n        0.76159416],\n       ...,\n       [0.76159416, 0.76159416, 0.7615942 , ..., 0.76159809, 0.76159416,\n        0.76159416],\n       [0.76159416, 0.76159416, 0.76159416, ..., 0.76159416, 0.76159809,\n        0.76159416],\n       [0.76159432, 0.76159416, 0.76159416, ..., 0.76159416, 0.76159416,\n        0.76159809]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_sig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.76159809, 0.76159416, 0.76159416, ..., 0.76159416, 0.76159416,\n       0.76159432])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_sig[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "indices = pd.Series(songs_df.index, index=songs_df['title'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "title\nEl hijo del pueblo        0\nPilots                    1\n006                       2\nEthos of Coercion         3\nRock-N-Rule               4\n                      ...  \nTyttö metsässä        19995\nInis Mona             19996\nI Can Tell            19997\nThe April Fools       19998\nDaría                 19999\nLength: 20000, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "idx = indices['Before He Kissed Me']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2 = indices['Night And Day']\n",
    "idx2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 0.7615941559557649)\n",
      "(1, 0.7615941798472373)\n",
      "(19999, 0.7615942580695211)\n",
      "(1, 0.7615941559557649)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "sig_scores = list(enumerate(songs_sig[idx]))\n",
    "print(sig_scores[-1])\n",
    "print(sig_scores[1])\n",
    "sig_scores2 = list(enumerate(songs_sig[idx2]))\n",
    "print(sig_scores2[-1])\n",
    "print(sig_scores2[1])\n",
    "print(type(sig_scores[1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "       song_id  sig_score\n9            9   0.761598\n15480    15480   0.761596\n16609    16609   0.761596\n5526      5526   0.761596\n8373      8373   0.761596\n...        ...        ...\n5298      5298   0.761594\n12823    12823   0.761594\n12816    12816   0.761594\n5306      5306   0.761594\n0            0   0.761594\n\n[20000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>sig_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.761598</td>\n    </tr>\n    <tr>\n      <th>15480</th>\n      <td>15480</td>\n      <td>0.761596</td>\n    </tr>\n    <tr>\n      <th>16609</th>\n      <td>16609</td>\n      <td>0.761596</td>\n    </tr>\n    <tr>\n      <th>5526</th>\n      <td>5526</td>\n      <td>0.761596</td>\n    </tr>\n    <tr>\n      <th>8373</th>\n      <td>8373</td>\n      <td>0.761596</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5298</th>\n      <td>5298</td>\n      <td>0.761594</td>\n    </tr>\n    <tr>\n      <th>12823</th>\n      <td>12823</td>\n      <td>0.761594</td>\n    </tr>\n    <tr>\n      <th>12816</th>\n      <td>12816</td>\n      <td>0.761594</td>\n    </tr>\n    <tr>\n      <th>5306</th>\n      <td>5306</td>\n      <td>0.761594</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.761594</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_scores_df = pd.DataFrame(sig_scores, columns=['song_id', 'sig_score'])\n",
    "sig_scores_df.sort_values(by='sig_score', ascending=False)\n",
    "\n",
    "sig_scores_df2 = pd.DataFrame(sig_scores2, columns=['song_id', 'sig_score'])\n",
    "sig_scores_df2.sort_values(by='sig_score', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "sig_scores_df = pd.DataFrame(sig_scores, columns=['song_id', 'sig_score'])\n",
    "sig_scores_df.set_index('song_id', inplace=True)\n",
    "\n",
    "sig_scores_df2 = pd.DataFrame(sig_scores2, columns=['song_id', 'sig_score'])\n",
    "sig_scores_df2.set_index('song_id', inplace=True)\n",
    "# sig_scores_df.sort_values(by='sig_score', ascending=False)\n",
    "\n",
    "result_df = sig_scores_df.add(sig_scores_df2)\n",
    "result_df = result_df.sort_values(by='sig_score', ascending=False)\n",
    "result_df = result_df[1:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 7:\n",
      "Waterlogged Broken Hope\n",
      "Night And Day The Maytals\n",
      "The Life Alicia Keys\n",
      "Skinhead Moonstomp Symarip\n",
      "Babies Pulp\n",
      "Will You Be OK 702\n",
      "Inner Smile Texas\n",
      "Philby Rory Gallagher\n",
      "Tomorrow May Never Come The Spinners\n"
     ]
    }
   ],
   "source": [
    "print(f'Recommendations for {idx}:')\n",
    "for index, song_score in result_df.iterrows():\n",
    "    # print(index)\n",
    "    # print(song_score[0])\n",
    "    # print(songs_df['title'].iloc[index])\n",
    "    # print(song_score)\n",
    "    print(songs_df['title'].iloc[index], songs_df['artist_name'].iloc[index])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[(17140, 0.7615980925843139),\n (6679, 0.7615946934019091),\n (16945, 0.7615946934019091),\n (18372, 0.7615946753420102),\n (5809, 0.7615946434644573),\n (12405, 0.761594615341704),\n (12947, 0.7615945966095496),\n (19732, 0.7615945928406871),\n (12072, 0.7615945801236044),\n (4867, 0.7615945403184269)]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_scores = list(enumerate(songs_sig[idx]))\n",
    "sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n",
    "sig_scores = sig_scores[1:11]\n",
    "sig_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waterlogged Broken Hope\n",
      "Gone Kissin Lunachicks\n",
      "Gone Kissin Lunachicks\n",
      "Flowers Grow Out of My Grave Dead Man's Bones\n",
      "When Pain Comes To Surface Skinlab\n",
      "Present Arrived Tom Verlaine\n",
      "Peace Senser\n",
      "Beautiful Mind The Verve\n",
      "Envelopes Another Day Ariel Pink's Haunted Graffiti\n",
      "Drifting Texas Sand Webb Pierce\n"
     ]
    }
   ],
   "source": [
    "for song_score in sig_scores:\n",
    "    print(songs_df['title'].iloc[song_score[0]], songs_df['artist_name'].iloc[song_score[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Content-based recommendation based on cosine similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "cosine_song_similarity = cosine_similarity(tfidf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.04216187],\n       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 1.        , ..., 0.01048144, 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.01048144, ..., 1.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n        0.        ],\n       [0.04216187, 0.        , 0.        , ..., 0.        , 0.        ,\n        1.        ]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_song_similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "20000"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cosine_song_similarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "indices = pd.Series(songs_df.index, index=songs_df['title'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = indices['Before He Kissed Me']\n",
    "idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2 = indices['Night And Day']\n",
    "idx2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.        , 0.        , 0.01800646, ..., 0.00988273, 0.        ,\n       0.02593921])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_song_similarity[idx2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "          score\n7      1.000000\n17140  1.000000\n16945  0.136524\n6679   0.136524\n18372  0.131936\n...         ...\n9440   0.000000\n9442   0.000000\n9446   0.000000\n9449   0.000000\n19999  0.000000\n\n[20000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>17140</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>16945</th>\n      <td>0.136524</td>\n    </tr>\n    <tr>\n      <th>6679</th>\n      <td>0.136524</td>\n    </tr>\n    <tr>\n      <th>18372</th>\n      <td>0.131936</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9440</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9442</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9446</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9449</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cosine_song_similarity[idx])\n",
    "df = pd.DataFrame(cosine_song_similarity[idx], columns=['score'])\n",
    "df2 = pd.DataFrame(cosine_song_similarity[idx2], columns=['score'])\n",
    "# df = df.add(df2)\n",
    "df.sort_values(by='score', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(cosine_song_similarity[idx])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cosine_song_similarity[idx])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "array([    7, 17140,  6679, 16945, 18372,  5809, 12405, 12947, 19732,\n       12072,  4867,  3948, 18692,   307,   794, 11696,   380, 18240,\n        7338, 16291,  4990, 13953,  2519,  6977,  6467,  2883,  5644,\n        1785,  1756,  4993,  5067,  9333,  4830,  7632, 13274, 18815,\n        9284, 15293, 19154, 18474,  1380,  7228,  2184, 17989, 11769,\n       15259, 17348, 18026,  6839], dtype=int64)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cosine_song_similarity[idx].argsort()[:-50:-1]\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.        , 1.        , 0.13652363, ..., 0.        , 0.        ,\n       0.        ])"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(cosine_song_similarity[idx])[::-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before He Kissed Me Lisa Brokop\n",
      "Waterlogged Broken Hope\n",
      "Gone Kissin Lunachicks\n",
      "Gone Kissin Lunachicks\n",
      "Flowers Grow Out of My Grave Dead Man's Bones\n",
      "When Pain Comes To Surface Skinlab\n",
      "Present Arrived Tom Verlaine\n",
      "Peace Senser\n",
      "Beautiful Mind The Verve\n",
      "Envelopes Another Day Ariel Pink's Haunted Graffiti\n",
      "Drifting Texas Sand Webb Pierce\n",
      "The Abandoned Ava Inferi\n",
      "Lay Some Flowers On My Grave Blind Willie McTell\n",
      "Hold Fast Call To Preserve\n",
      "Fish Mr. Scruff\n",
      "Come Death Blood Red Throne\n",
      "Home Again Beach House\n",
      "Mouth Machine Gun Our Last Night\n",
      "Fallen Angel Seelenkrank\n",
      "Settling Down Jerry Cantrell\n",
      "Gerontion A Silent Film\n",
      "The Grove Chuck Ragan\n",
      "Lucky Lips Gale Storm\n",
      "Crushed Eighteen Visions\n",
      "Upon Raging Waves Mithotyn\n",
      "Deep Dark Side Cowboys\n",
      "Under My Skin Paffendorf\n",
      "Your Place In The World The Space Brothers\n",
      "This Would Be Paradise Melissa Auf der Maur\n",
      "Soft Lips Hank Thompson\n",
      "Lay Your Body Down Divinyls\n",
      "The Morning After Tankard\n",
      "Bukkake Tsunami Cattle Decapitation\n",
      "Not Now Coffin Break\n",
      "Devotion Luscious Jackson\n",
      "Peace Be Upon Us Sheryl Crow\n",
      "Last Gravity Kills\n",
      "Henceforth Macbeth\n",
      "Sleeping Beneath The Lawn Spiritus Mortis\n",
      "The Beachcomber Silje Nergaard\n",
      "Sherpa Le Loup\n",
      "On And On Piebald\n",
      "Ocean Cerys Matthews\n",
      "Dig Ophelia Rasputina\n",
      "Release Beyond The Embrace\n",
      "Lost Passion Immolation\n",
      "Centennial Legend Edenbridge\n",
      "Stuck In The Sand Miss Li\n",
      "Bottle Song Rose Chronicles\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(songs_df['title'].iloc[result], songs_df['artist_name'].iloc[result])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get songs user has listened to"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def database_data_to_dataframe(data):\n",
    "    headers = data[0].dict().keys()\n",
    "    data_values = [d.dict().values() for d in data]\n",
    "    df = pd.DataFrame(data_values, columns=headers)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from models.msd_triplet import MsdTriplet\n",
    "from dao.dao_msd_triplets import DAOMsdTriplets\n",
    "\n",
    "dao_triplets: DAOMsdTriplets = DAOMsdTriplets()\n",
    "triplets: List[MsdTriplet] = dao_triplets.find_all()\n",
    "triplets_df = database_data_to_dataframe(triplets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def get_songs_user_has_listened_to(triplets_df, user_id):\n",
    "    return triplets_df.loc[triplets_df['user_id'] == user_id, 'song_id']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "songs = get_songs_user_has_listened_to(triplets_df, 'b80344d063b5ccb3212f76538f3d9e43d87dca9e')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "45"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "['SOAKIMP12A8C130995',\n 'SOBBMDR12A8C13253B',\n 'SOBXHDL12A81C204C0',\n 'SOBYHAJ12A6701BF1D',\n 'SODACBL12A8C13C273',\n 'SODDNQT12A6D4F5F7E',\n 'SODXRTY12AB0180F3B',\n 'SOFGUAY12AB017B0A8',\n 'SOFRQTD12A81C233C0',\n 'SOHQWYZ12A6D4FA701',\n 'SOIYTOA12A6D4F9A23',\n 'SOIZAZL12A6701C53B',\n 'SOJNNUA12A8AE48C7A',\n 'SOJPFQG12A58A7833A',\n 'SOKRIMP12A6D4F5DA3',\n 'SOLLGNU12AF72A4D4F',\n 'SOMGIYR12AB0187973',\n 'SOMLMKI12A81C204BC',\n 'SOMSQJY12A8C138539',\n 'SONSAEZ12A8C138D7A',\n 'SOOKGRB12A8C13CD66',\n 'SOPCVQE12AC468AF36',\n 'SOQIVUD12AB01821D2',\n 'SOQJLDY12AAF3B456D',\n 'SOQLCKR12A81C22440',\n 'SORPMYJ12AF729EB90',\n 'SORQHCG12A58A7EEBA',\n 'SORUFVF12AB018230B',\n 'SORWLTW12A670208FA',\n 'SORZASF12A6D4F8CFA',\n 'SOSYBEV12AB0182933',\n 'SOTFATN12A6D4FA74D',\n 'SOTLVCL12AB0182D22',\n 'SOTRSFZ12A8C142BF6',\n 'SOUKXIN12A8C133C7F',\n 'SOVHRGF12A8C13852F',\n 'SOVQEYZ12A8C1379D8',\n 'SOVYIYI12A8C138D88',\n 'SOWQLXP12AF72A08A2',\n 'SOWSPUS12AC468BEE3',\n 'SOXMIUS12A8C13CD59',\n 'SOXRXDG12A8C131DE5',\n 'SOXZQDE12A8C135833',\n 'SOYHEPA12A8C13097F',\n 'SOZOBWN12A8C130999']"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
