{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Environment configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: DeepSaki==0.1.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 1)) (0.1.3)\n",
      "Requirement already satisfied: keras==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: tensorboard==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 3)) (2.10.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.6.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: tensorflow==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 6)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-addons==0.19.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 7)) (0.19.0)\n",
      "Requirement already satisfied: tensorflow-estimator==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 8)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 9)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.29.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 10)) (0.29.0)\n",
      "Requirement already satisfied: pydantic==1.10.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 11)) (1.10.4)\n",
      "Requirement already satisfied: pymongo==4.3.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 12)) (4.3.3)\n",
      "Requirement already satisfied: pandas in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from DeepSaki==0.1.3->-r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: numpy in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from DeepSaki==0.1.3->-r requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.28.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (1.51.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (3.19.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (65.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: packaging in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (23.1.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (15.0.6.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (3.7.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow-addons==0.19.0->-r requirements.txt (line 7)) (2.13.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pymongo==4.3.3->-r requirements.txt (line 12)) (2.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (5.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from markdown>=2.6.8->tensorboard==2.10.0->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pandas->DeepSaki==0.1.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pandas->DeepSaki==0.1.3->-r requirements.txt (line 1)) (2022.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Upgrading pip which will be used to install all libraries\n",
    "!pip install -r requirements.txt\n",
    "# !pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on single GPU  /device:GPU:0\n",
      "Number of accelerators:  1\n",
      "____________________________________________________________________________________\n",
      "Device List: \n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1824674675494836633\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1721342363\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8194716375156599408\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# to check if working on GPU\n",
    "# !pip install DeepSaki\n",
    "from tensorflow import keras\n",
    "import DeepSaki\n",
    "strategy, RUNTIME_ENVIRONMENT, hw_accelerator_handle = DeepSaki.utils.DetectHw()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Content-based filtering using TF-IDF score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/0_raw/msd_data/song_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m song_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/0_raw/msd_data/song_data.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m triplets_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/0_raw/msd_data/triplets_file.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/0_raw/msd_data/song_data.csv'"
     ]
    }
   ],
   "source": [
    "song_df = pd.read_csv('../data/0_raw/msd_data/song_data.csv', sep=\",\", header=0)\n",
    "triplets_df = pd.read_csv('../data/0_raw/msd_data/triplets_file.csv', sep=\",\", header=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "# from ../models/msd_song import MsdSongWithLyrics\n",
    "from models.msd_song import MsdSongWithLyrics\n",
    "from dao.dao_msd_songs_with_lyrics import DAOMsdSongsWithLyrics\n",
    "\n",
    "dao_songs_with_lyrics: DAOMsdSongsWithLyrics = DAOMsdSongsWithLyrics()\n",
    "songs: List[MsdSongWithLyrics] = dao_songs_with_lyrics.find_many_by_query({'lyrics': {'$ne':None}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "              song_id               title  \\\n0  SOLJTLX12AB01890ED  El hijo del pueblo   \n1  SOMPVQB12A8C1379BB              Pilots   \n2  SOSDCFG12AB0184647                 006   \n3  SOKOVRQ12A8C142811   Ethos of Coercion   \n4  SOIMMJJ12AF72AD643         Rock-N-Rule   \n\n                                release      artist_name  year   tag features  \\\n0               32 Grandes Éxitos  CD 2    Jorge Negrete  1997   pop       []   \n1                             The Loyal        Tiger Lou  2005   pop       []   \n2                            Lena 20 År  Lena Philipsson  1998   pop       []   \n3                Descend Into Depravity      Dying Fetus  2009  rock       []   \n4  I'm Only A Man (Bonus Track Version)            Emery  2007  rock       []   \n\n                                              lyrics  \n0  Es mi orgullo haber nacido en el barrio más hu...  \n1  Raise the chandelier light the candels dear i ...  \n2  I had come in the name of love\\nWith a mission...  \n3  Castigation of the offenders, no punishment ou...  \n4  [Intro]\\nThis is a waking up\\nThis is your fin...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>title</th>\n      <th>release</th>\n      <th>artist_name</th>\n      <th>year</th>\n      <th>tag</th>\n      <th>features</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SOLJTLX12AB01890ED</td>\n      <td>El hijo del pueblo</td>\n      <td>32 Grandes Éxitos  CD 2</td>\n      <td>Jorge Negrete</td>\n      <td>1997</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>Es mi orgullo haber nacido en el barrio más hu...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SOMPVQB12A8C1379BB</td>\n      <td>Pilots</td>\n      <td>The Loyal</td>\n      <td>Tiger Lou</td>\n      <td>2005</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>Raise the chandelier light the candels dear i ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SOSDCFG12AB0184647</td>\n      <td>006</td>\n      <td>Lena 20 År</td>\n      <td>Lena Philipsson</td>\n      <td>1998</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>I had come in the name of love\\nWith a mission...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SOKOVRQ12A8C142811</td>\n      <td>Ethos of Coercion</td>\n      <td>Descend Into Depravity</td>\n      <td>Dying Fetus</td>\n      <td>2009</td>\n      <td>rock</td>\n      <td>[]</td>\n      <td>Castigation of the offenders, no punishment ou...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SOIMMJJ12AF72AD643</td>\n      <td>Rock-N-Rule</td>\n      <td>I'm Only A Man (Bonus Track Version)</td>\n      <td>Emery</td>\n      <td>2007</td>\n      <td>rock</td>\n      <td>[]</td>\n      <td>[Intro]\\nThis is a waking up\\nThis is your fin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = songs[0].dict().keys()\n",
    "songs_values = [song.dict().values() for song in songs]\n",
    "songs_df = pd.DataFrame(songs_values, columns=headers)\n",
    "songs_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from scikit-learn) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ewakae\\AppData\\Local\\Temp\\ipykernel_15628\\2959928106.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  songs_df['lyrics'] = songs_df['lyrics'].str.replace(r'\\n', ' ')\n"
     ]
    }
   ],
   "source": [
    "songs_df['lyrics'] = songs_df['lyrics'].str.replace(r'\\n', ' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "0         Es mi orgullo haber nacido en el barrio más hu...\n1         Raise the chandelier light the candels dear i ...\n2         I had come in the name of love With a mission ...\n3         Castigation of the offenders, no punishment ou...\n4         [Intro] This is a waking up This is your final...\n                                ...                        \n181329    Yesterday I went outside And all my grass had ...\n181330    Big girls like telling boys that shove \"fact i...\n181331    [Verse 1] Think of me as your soldier The man ...\n181332    Interrotte speranze, eterna fede Fiamme e stra...\n181333    Where do you go with all of those scars They r...\nName: lyrics, Length: 181334, dtype: object"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df['lyrics']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: colorama in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ewakae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U nltk\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "final_stopwords_list = stopwords.words('english') + stopwords.words('french') + stopwords.words('spanish') + stopwords.words('swedish')\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words=final_stopwords_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "songs_df = songs_df[:20000]\n",
    "tfidf_matrix = tfidf.fit_transform(songs_df['lyrics'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<20000x106683 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1170789 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "(20000, 106683)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Content-based recommendation based on sigmoid kernel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "\n",
    "songs_sig = sigmoid_kernel(tfidf_matrix, tfidf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.76159809, 0.76159416, 0.76159416, ..., 0.76159416, 0.76159416,\n       0.76159432])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_sig[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "indices = pd.Series(songs_df.index, index=songs_df['title'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "title\nEl hijo del pueblo        0\nPilots                    1\n006                       2\nEthos of Coercion         3\nRock-N-Rule               4\n                      ...  \nTyttö metsässä        19995\nInis Mona             19996\nI Can Tell            19997\nThe April Fools       19998\nDaría                 19999\nLength: 20000, dtype: int64"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "idx = indices['Before He Kissed Me']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "[(17140, 0.7615980925843139),\n (6679, 0.7615946934019091),\n (16945, 0.7615946934019091),\n (18372, 0.7615946753420102),\n (5809, 0.7615946434644573),\n (12405, 0.761594615341704),\n (12947, 0.7615945966095496),\n (19732, 0.7615945928406871),\n (12072, 0.7615945801236044),\n (4867, 0.7615945403184269)]"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_scores = list(enumerate(songs_sig[idx]))\n",
    "sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n",
    "sig_scores = sig_scores[1:11]\n",
    "sig_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waterlogged Broken Hope\n",
      "Gone Kissin Lunachicks\n",
      "Gone Kissin Lunachicks\n",
      "Flowers Grow Out of My Grave Dead Man's Bones\n",
      "When Pain Comes To Surface Skinlab\n",
      "Present Arrived Tom Verlaine\n",
      "Peace Senser\n",
      "Beautiful Mind The Verve\n",
      "Envelopes Another Day Ariel Pink's Haunted Graffiti\n",
      "Drifting Texas Sand Webb Pierce\n"
     ]
    }
   ],
   "source": [
    "for song_score in sig_scores:\n",
    "    print(songs_df['title'].iloc[song_score[0]], songs_df['artist_name'].iloc[song_score[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Content-based recommendation based on cosine similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "cosine_song_similarity = cosine_similarity(tfidf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.04216187],\n       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 1.        , ..., 0.01048144, 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.01048144, ..., 1.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n        0.        ],\n       [0.04216187, 0.        , 0.        , ..., 0.        , 0.        ,\n        1.        ]])"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_song_similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "20000"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cosine_song_similarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "indices = pd.Series(songs_df.index, index=songs_df['title'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = indices['Before He Kissed Me']\n",
    "idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cosine_song_similarity[idx])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.        , 0.00606898, 0.00161058, ..., 0.        , 0.        ,\n       0.        ])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_song_similarity[idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "results = cosine_song_similarity[idx].argsort()[:-50:-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before He Kissed Me Lisa Brokop\n",
      "Waterlogged Broken Hope\n",
      "Gone Kissin Lunachicks\n",
      "Gone Kissin Lunachicks\n",
      "Flowers Grow Out of My Grave Dead Man's Bones\n",
      "When Pain Comes To Surface Skinlab\n",
      "Present Arrived Tom Verlaine\n",
      "Peace Senser\n",
      "Beautiful Mind The Verve\n",
      "Envelopes Another Day Ariel Pink's Haunted Graffiti\n",
      "Drifting Texas Sand Webb Pierce\n",
      "The Abandoned Ava Inferi\n",
      "Lay Some Flowers On My Grave Blind Willie McTell\n",
      "Hold Fast Call To Preserve\n",
      "Fish Mr. Scruff\n",
      "Come Death Blood Red Throne\n",
      "Home Again Beach House\n",
      "Mouth Machine Gun Our Last Night\n",
      "Fallen Angel Seelenkrank\n",
      "Settling Down Jerry Cantrell\n",
      "Gerontion A Silent Film\n",
      "The Grove Chuck Ragan\n",
      "Lucky Lips Gale Storm\n",
      "Crushed Eighteen Visions\n",
      "Upon Raging Waves Mithotyn\n",
      "Deep Dark Side Cowboys\n",
      "Under My Skin Paffendorf\n",
      "Your Place In The World The Space Brothers\n",
      "This Would Be Paradise Melissa Auf der Maur\n",
      "Soft Lips Hank Thompson\n",
      "Lay Your Body Down Divinyls\n",
      "The Morning After Tankard\n",
      "Bukkake Tsunami Cattle Decapitation\n",
      "Not Now Coffin Break\n",
      "Devotion Luscious Jackson\n",
      "Peace Be Upon Us Sheryl Crow\n",
      "Last Gravity Kills\n",
      "Henceforth Macbeth\n",
      "Sleeping Beneath The Lawn Spiritus Mortis\n",
      "The Beachcomber Silje Nergaard\n",
      "Sherpa Le Loup\n",
      "On And On Piebald\n",
      "Ocean Cerys Matthews\n",
      "Dig Ophelia Rasputina\n",
      "Release Beyond The Embrace\n",
      "Lost Passion Immolation\n",
      "Centennial Legend Edenbridge\n",
      "Stuck In The Sand Miss Li\n",
      "Bottle Song Rose Chronicles\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(songs_df['title'].iloc[result], songs_df['artist_name'].iloc[result])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
