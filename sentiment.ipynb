{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Environment configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: DeepSaki==0.1.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 1)) (0.1.3)\n",
      "Requirement already satisfied: keras==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: tensorboard==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 3)) (2.10.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.6.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: tensorflow==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 6)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-addons==0.19.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 7)) (0.19.0)\n",
      "Requirement already satisfied: tensorflow-estimator==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 8)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.10.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 9)) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.29.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 10)) (0.29.0)\n",
      "Requirement already satisfied: pydantic~=1.10.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from -r requirements.txt (line 11)) (1.10.4)\n",
      "Collecting pymongo~=4.3.3\n",
      "  Using cached pymongo-4.3.3-cp39-cp39-win_amd64.whl (382 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: numpy in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from DeepSaki==0.1.3->-r requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: pandas in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from DeepSaki==0.1.3->-r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (1.51.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (2.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (65.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (3.19.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorboard==2.10.0->-r requirements.txt (line 3)) (0.37.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (15.0.6.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (23.1.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: packaging in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow==2.10.0->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: typeguard>=2.7 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tensorflow-addons==0.19.0->-r requirements.txt (line 7)) (2.13.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pymongo~=4.3.3->-r requirements.txt (line 12)) (2.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers->-r requirements.txt (line 13)) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers->-r requirements.txt (line 13)) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers->-r requirements.txt (line 13)) (4.64.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from transformers->-r requirements.txt (line 13)) (6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (5.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from markdown>=2.6.8->tensorboard==2.10.0->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.10.0->-r requirements.txt (line 3)) (2022.6.15)\n",
      "Requirement already satisfied: colorama in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from tqdm>=4.27->transformers->-r requirements.txt (line 13)) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pandas->DeepSaki==0.1.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pandas->DeepSaki==0.1.3->-r requirements.txt (line 1)) (2022.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.10.0->-r requirements.txt (line 3)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.10.0->-r requirements.txt (line 3)) (3.2.2)\n",
      "Installing collected packages: pymongo, filelock, huggingface-hub, transformers\n",
      "  Attempting uninstall: pymongo\n",
      "    Found existing installation: pymongo 3.12.3\n",
      "    Uninstalling pymongo-3.12.3:\n",
      "      Successfully uninstalled pymongo-3.12.3\n",
      "Successfully installed filelock-3.9.0 huggingface-hub-0.11.1 pymongo-4.3.3 transformers-4.25.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ymongo (d:\\dev\\anaconda3\\envs\\gpu2\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Upgrading pip which will be used to install all libraries\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on single GPU  /device:GPU:0\n",
      "Number of accelerators:  1\n",
      "____________________________________________________________________________________\n",
      "Device List: \n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7780481143290808895\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1721342363\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3192076693052380548\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# to check if working on GPU\n",
    "# !pip install DeepSaki\n",
    "from tensorflow import keras\n",
    "import DeepSaki\n",
    "strategy, RUNTIME_ENVIRONMENT, hw_accelerator_handle = DeepSaki.utils.DetectHw()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import songs with lyrics from MongoDB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# from ../models/msd_song import MsdSongWithLyrics\n",
    "from models.msd_song import MsdSongWithLyrics\n",
    "from dao.dao_msd_songs_with_lyrics import DAOMsdSongsWithLyrics\n",
    "\n",
    "dao_songs_with_lyrics: DAOMsdSongsWithLyrics = DAOMsdSongsWithLyrics(name=\"songs_with_lyrics\")\n",
    "songs: List[MsdSongWithLyrics] = dao_songs_with_lyrics.find_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "              song_id               title  \\\n0  SOLJTLX12AB01890ED  El hijo del pueblo   \n1  SOMPVQB12A8C1379BB              Pilots   \n2  SOSDCFG12AB0184647                 006   \n3  SOKOVRQ12A8C142811   Ethos of Coercion   \n4  SOIMMJJ12AF72AD643         Rock-N-Rule   \n\n                                release      artist_name  year   tag features  \\\n0               32 Grandes Éxitos  CD 2    Jorge Negrete  1997   pop       []   \n1                             The Loyal        Tiger Lou  2005   pop       []   \n2                            Lena 20 År  Lena Philipsson  1998   pop       []   \n3                Descend Into Depravity      Dying Fetus  2009  rock       []   \n4  I'm Only A Man (Bonus Track Version)            Emery  2007  rock       []   \n\n                                              lyrics  \n0  Es mi orgullo haber nacido en el barrio más hu...  \n1  Raise the chandelier light the candels dear i ...  \n2  I had come in the name of love\\nWith a mission...  \n3  Castigation of the offenders, no punishment ou...  \n4  [Intro]\\nThis is a waking up\\nThis is your fin...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>title</th>\n      <th>release</th>\n      <th>artist_name</th>\n      <th>year</th>\n      <th>tag</th>\n      <th>features</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SOLJTLX12AB01890ED</td>\n      <td>El hijo del pueblo</td>\n      <td>32 Grandes Éxitos  CD 2</td>\n      <td>Jorge Negrete</td>\n      <td>1997</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>Es mi orgullo haber nacido en el barrio más hu...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SOMPVQB12A8C1379BB</td>\n      <td>Pilots</td>\n      <td>The Loyal</td>\n      <td>Tiger Lou</td>\n      <td>2005</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>Raise the chandelier light the candels dear i ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SOSDCFG12AB0184647</td>\n      <td>006</td>\n      <td>Lena 20 År</td>\n      <td>Lena Philipsson</td>\n      <td>1998</td>\n      <td>pop</td>\n      <td>[]</td>\n      <td>I had come in the name of love\\nWith a mission...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SOKOVRQ12A8C142811</td>\n      <td>Ethos of Coercion</td>\n      <td>Descend Into Depravity</td>\n      <td>Dying Fetus</td>\n      <td>2009</td>\n      <td>rock</td>\n      <td>[]</td>\n      <td>Castigation of the offenders, no punishment ou...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SOIMMJJ12AF72AD643</td>\n      <td>Rock-N-Rule</td>\n      <td>I'm Only A Man (Bonus Track Version)</td>\n      <td>Emery</td>\n      <td>2007</td>\n      <td>rock</td>\n      <td>[]</td>\n      <td>[Intro]\\nThis is a waking up\\nThis is your fin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = songs[0].dict().keys()\n",
    "songs_values = [song.dict().values() for song in songs]\n",
    "songs_df = pd.DataFrame(songs_values, columns=headers)\n",
    "songs_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m song_id \u001B[38;5;129;01min\u001B[39;00m songs_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msong_id\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m----> 8\u001B[0m     triplets: List[MsdTriplet] \u001B[38;5;241m=\u001B[39m \u001B[43mdao_songs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_many_by_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msong_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msong_id\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(triplets) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     10\u001B[0m         count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mE:\\OneDrive - Politechnika Warszawska\\Studia\\semestr7\\MIR\\music_recommendation\\dao\\dao_base.py:41\u001B[0m, in \u001B[0;36mDAOBase.find_many_by_query\u001B[1;34m(self, query)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_many_by_query\u001B[39m(\u001B[38;5;28mself\u001B[39m, query: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BaseModel]:\n\u001B[0;32m     40\u001B[0m     result: MongoCursor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollection\u001B[38;5;241m.\u001B[39mfind(query)\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_in_db(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdoc) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m]\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\cursor.py:1248\u001B[0m, in \u001B[0;36mCursor.next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__empty:\n\u001B[0;32m   1247\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m-> 1248\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__data) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_refresh\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1249\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__data\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[0;32m   1250\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\cursor.py:1165\u001B[0m, in \u001B[0;36mCursor._refresh\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1143\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidOperation(\n\u001B[0;32m   1144\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhint\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is required when using the min/max query\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1145\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m option to ensure the query utilizes the correct index\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1146\u001B[0m         )\n\u001B[0;32m   1147\u001B[0m     q \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_class(\n\u001B[0;32m   1148\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__query_flags,\n\u001B[0;32m   1149\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__collection\u001B[38;5;241m.\u001B[39mdatabase\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1163\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__exhaust,\n\u001B[0;32m   1164\u001B[0m     )\n\u001B[1;32m-> 1165\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1166\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__id:  \u001B[38;5;66;03m# Get More\u001B[39;00m\n\u001B[0;32m   1167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__limit:\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\cursor.py:1052\u001B[0m, in \u001B[0;36mCursor.__send_message\u001B[1;34m(self, operation)\u001B[0m\n\u001B[0;32m   1049\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m InvalidOperation(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexhaust cursors do not support auto encryption\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1051\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1052\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_operation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1053\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack_response\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maddress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__address\u001B[49m\n\u001B[0;32m   1054\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1055\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OperationFailure \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m   1056\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mcode \u001B[38;5;129;01min\u001B[39;00m _CURSOR_CLOSED_ERRORS \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__exhaust:\n\u001B[0;32m   1057\u001B[0m         \u001B[38;5;66;03m# Don't send killCursors because the cursor is already closed.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\_csot.py:105\u001B[0m, in \u001B[0;36mapply.<locals>.csot_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m _TimeoutContext(timeout):\n\u001B[0;32m    104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\mongo_client.py:1330\u001B[0m, in \u001B[0;36mMongoClient._run_operation\u001B[1;34m(self, operation, unpack_res, address)\u001B[0m\n\u001B[0;32m   1325\u001B[0m     operation\u001B[38;5;241m.\u001B[39mreset()  \u001B[38;5;66;03m# Reset op in case of retry.\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m server\u001B[38;5;241m.\u001B[39mrun_operation(\n\u001B[0;32m   1327\u001B[0m         sock_info, operation, read_preference, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_listeners, unpack_res\n\u001B[0;32m   1328\u001B[0m     )\n\u001B[1;32m-> 1330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retryable_read\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1331\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_cmd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1332\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_preference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1333\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1334\u001B[0m \u001B[43m    \u001B[49m\u001B[43maddress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maddress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1335\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretryable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moperation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Query\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1336\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\_csot.py:105\u001B[0m, in \u001B[0;36mapply.<locals>.csot_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m _TimeoutContext(timeout):\n\u001B[0;32m    104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\mongo_client.py:1448\u001B[0m, in \u001B[0;36mMongoClient._retryable_read\u001B[1;34m(self, func, read_pref, session, address, retryable)\u001B[0m\n\u001B[0;32m   1446\u001B[0m             \u001B[38;5;28;01massert\u001B[39;00m last_error \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1447\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m last_error\n\u001B[1;32m-> 1448\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msock_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_pref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1449\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ServerSelectionTimeoutError:\n\u001B[0;32m   1450\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m retrying:\n\u001B[0;32m   1451\u001B[0m         \u001B[38;5;66;03m# The application may think the write was never attempted\u001B[39;00m\n\u001B[0;32m   1452\u001B[0m         \u001B[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001B[39;00m\n\u001B[0;32m   1453\u001B[0m         \u001B[38;5;66;03m# attempt. Raise the original exception instead.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\mongo_client.py:1326\u001B[0m, in \u001B[0;36mMongoClient._run_operation.<locals>._cmd\u001B[1;34m(session, server, sock_info, read_preference)\u001B[0m\n\u001B[0;32m   1324\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cmd\u001B[39m(session, server, sock_info, read_preference):\n\u001B[0;32m   1325\u001B[0m     operation\u001B[38;5;241m.\u001B[39mreset()  \u001B[38;5;66;03m# Reset op in case of retry.\u001B[39;00m\n\u001B[1;32m-> 1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_operation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1327\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_preference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event_listeners\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munpack_res\u001B[49m\n\u001B[0;32m   1328\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\server.py:115\u001B[0m, in \u001B[0;36mServer.run_operation\u001B[1;34m(self, sock_info, operation, read_preference, listeners, unpack_res)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    114\u001B[0m     sock_info\u001B[38;5;241m.\u001B[39msend_message(data, max_doc_size)\n\u001B[1;32m--> 115\u001B[0m     reply \u001B[38;5;241m=\u001B[39m \u001B[43msock_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreceive_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;66;03m# Unpack and check for command errors.\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cmd:\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\pool.py:821\u001B[0m, in \u001B[0;36mSocketInfo.receive_message\u001B[1;34m(self, request_id)\u001B[0m\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m receive_message(\u001B[38;5;28mself\u001B[39m, request_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_message_size)\n\u001B[0;32m    820\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m--> 821\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_connection_failure\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\pool.py:819\u001B[0m, in \u001B[0;36mSocketInfo.receive_message\u001B[1;34m(self, request_id)\u001B[0m\n\u001B[0;32m    814\u001B[0m \u001B[38;5;124;03m\"\"\"Receive a raw BSON message or raise ConnectionFailure.\u001B[39;00m\n\u001B[0;32m    815\u001B[0m \n\u001B[0;32m    816\u001B[0m \u001B[38;5;124;03mIf any exception is raised, the socket is closed.\u001B[39;00m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 819\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreceive_message\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_message_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_connection_failure(error)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\network.py:217\u001B[0m, in \u001B[0;36mreceive_message\u001B[1;34m(sock_info, request_id, max_message_size)\u001B[0m\n\u001B[0;32m    214\u001B[0m         deadline \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;66;03m# Ignore the response's request id.\u001B[39;00m\n\u001B[0;32m    216\u001B[0m length, _, response_to, op_code \u001B[38;5;241m=\u001B[39m _UNPACK_HEADER(\n\u001B[1;32m--> 217\u001B[0m     \u001B[43m_receive_data_on_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43msock_info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m )\n\u001B[0;32m    219\u001B[0m \u001B[38;5;66;03m# No request_id for exhaust cursor \"getMore\".\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m request_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\pymongo\\network.py:299\u001B[0m, in \u001B[0;36m_receive_data_on_socket\u001B[1;34m(sock_info, length, deadline)\u001B[0m\n\u001B[0;32m    297\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _csot\u001B[38;5;241m.\u001B[39mget_timeout():\n\u001B[0;32m    298\u001B[0m         sock_info\u001B[38;5;241m.\u001B[39mset_socket_timeout(\u001B[38;5;28mmax\u001B[39m(deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic(), \u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m--> 299\u001B[0m     chunk_length \u001B[38;5;241m=\u001B[39m \u001B[43msock_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmv\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbytes_read\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    300\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m BLOCKING_IO_ERRORS:\n\u001B[0;32m    301\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mtimeout(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimed out\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from dao.dao_msd_triplets import DAOMsdTriplets\n",
    "from models.msd_triplet import MsdTriplet\n",
    "dao_songs: DAOMsdTriplets = DAOMsdTriplets()\n",
    "\n",
    "done = 0\n",
    "count = 0\n",
    "for song_id in songs_df['song_id']:\n",
    "    triplets: List[MsdTriplet] = dao_songs.find_many_by_query({'song_id': song_id})\n",
    "    if len(triplets) != 0:\n",
    "        count += 1\n",
    "    done += 1\n",
    "    if not done % 10:\n",
    "        print(done)\n",
    "print(count) # Everything is empty :(( -> cant use supervised sentiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"roberta\" \"                 f\"(type TFRobertaMainLayer).\n\n{{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50265,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2]\n\nCall arguments received by layer \"roberta\" \"                 f\"(type TFRobertaMainLayer):\n  • input_ids=tf.Tensor(shape=(3, 5), dtype=int32)\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m gpu_options \u001B[38;5;241m=\u001B[39m GPUOptions(allow_growth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m session \u001B[38;5;241m=\u001B[39m InteractiveSession(config\u001B[38;5;241m=\u001B[39mConfigProto(gpu_options\u001B[38;5;241m=\u001B[39mgpu_options))\n\u001B[1;32m----> 7\u001B[0m sentiment_analysis \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msentiment-analysis\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msiebert/sentiment-roberta-large-english\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(sentiment_analysis(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI love my girl\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\pipelines\\__init__.py:724\u001B[0m, in \u001B[0;36mpipeline\u001B[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[0m\n\u001B[0;32m    720\u001B[0m \u001B[38;5;66;03m# Infer the framework from the model\u001B[39;00m\n\u001B[0;32m    721\u001B[0m \u001B[38;5;66;03m# Forced if framework already defined, inferred if it's None\u001B[39;00m\n\u001B[0;32m    722\u001B[0m \u001B[38;5;66;03m# Will load the correct model if possible\u001B[39;00m\n\u001B[0;32m    723\u001B[0m model_classes \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m: targeted_task[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m: targeted_task[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m]}\n\u001B[1;32m--> 724\u001B[0m framework, model \u001B[38;5;241m=\u001B[39m infer_framework_load_model(\n\u001B[0;32m    725\u001B[0m     model,\n\u001B[0;32m    726\u001B[0m     model_classes\u001B[38;5;241m=\u001B[39mmodel_classes,\n\u001B[0;32m    727\u001B[0m     config\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[0;32m    728\u001B[0m     framework\u001B[38;5;241m=\u001B[39mframework,\n\u001B[0;32m    729\u001B[0m     task\u001B[38;5;241m=\u001B[39mtask,\n\u001B[0;32m    730\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs,\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m    732\u001B[0m )\n\u001B[0;32m    734\u001B[0m model_config \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\n\u001B[0;32m    735\u001B[0m hub_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_commit_hash\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\pipelines\\base.py:257\u001B[0m, in \u001B[0;36minfer_framework_load_model\u001B[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001B[0m\n\u001B[0;32m    251\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    253\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to load the model with Tensorflow.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    254\u001B[0m     )\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 257\u001B[0m     model \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    259\u001B[0m         model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:463\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    462\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    464\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    465\u001B[0m     )\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    469\u001B[0m )\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\modeling_tf_utils.py:2734\u001B[0m, in \u001B[0;36mTFPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   2732\u001B[0m         model(model\u001B[38;5;241m.\u001B[39mdummy_inputs)  \u001B[38;5;66;03m# build the network with dummy inputs\u001B[39;00m\n\u001B[0;32m   2733\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2734\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdummy_inputs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# build the network with dummy inputs\u001B[39;00m\n\u001B[0;32m   2736\u001B[0m \u001B[38;5;66;03m# 'by_name' allow us to do transfer learning by skipping/adding layers\u001B[39;00m\n\u001B[0;32m   2737\u001B[0m \u001B[38;5;66;03m# see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1339-L1357\u001B[39;00m\n\u001B[0;32m   2738\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\modeling_tf_utils.py:432\u001B[0m, in \u001B[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    429\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\n\u001B[0;32m    431\u001B[0m unpacked_inputs \u001B[38;5;241m=\u001B[39m input_processing(func, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_args_and_kwargs)\n\u001B[1;32m--> 432\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munpacked_inputs)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py:1374\u001B[0m, in \u001B[0;36mTFRobertaForSequenceClassification.call\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001B[0m\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;129m@unpack_inputs\u001B[39m\n\u001B[0;32m   1345\u001B[0m \u001B[38;5;129m@add_start_docstrings_to_model_forward\u001B[39m(ROBERTA_INPUTS_DOCSTRING\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size, sequence_length\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;129m@add_code_sample_docstrings\u001B[39m(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1366\u001B[0m     training: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1367\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[TFSequenceClassifierOutput, Tuple[tf\u001B[38;5;241m.\u001B[39mTensor]]:\n\u001B[0;32m   1368\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1369\u001B[0m \u001B[38;5;124;03m    labels (`tf.Tensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1371\u001B[0m \u001B[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1372\u001B[0m \u001B[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1374\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroberta\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1375\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1376\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1377\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1378\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1379\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1380\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1381\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1382\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1384\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1385\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1386\u001B[0m     sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1387\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(sequence_output, training\u001B[38;5;241m=\u001B[39mtraining)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\modeling_tf_utils.py:432\u001B[0m, in \u001B[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    429\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\n\u001B[0;32m    431\u001B[0m unpacked_inputs \u001B[38;5;241m=\u001B[39m input_processing(func, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_args_and_kwargs)\n\u001B[1;32m--> 432\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munpacked_inputs)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py:665\u001B[0m, in \u001B[0;36mTFRobertaMainLayer.call\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001B[0m\n\u001B[0;32m    662\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m token_type_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    663\u001B[0m     token_type_ids \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfill(dims\u001B[38;5;241m=\u001B[39minput_shape, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 665\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    666\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001B[39;00m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001B[39;00m\n\u001B[0;32m    676\u001B[0m \u001B[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001B[39;00m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001B[39;00m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001B[39;00m\n\u001B[0;32m    679\u001B[0m attention_mask_shape \u001B[38;5;241m=\u001B[39m shape_list(attention_mask)\n",
      "File \u001B[1;32mD:\\Dev\\anaconda3\\envs\\gpu2\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py:95\u001B[0m, in \u001B[0;36mTFRobertaEmbeddings.build\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_shape: tf\u001B[38;5;241m.\u001B[39mTensorShape):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mname_scope(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword_embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m---> 95\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_weight(\n\u001B[0;32m     96\u001B[0m             name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     97\u001B[0m             shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size],\n\u001B[0;32m     98\u001B[0m             initializer\u001B[38;5;241m=\u001B[39mget_initializer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitializer_range),\n\u001B[0;32m     99\u001B[0m         )\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mname_scope(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_type_embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    102\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken_type_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_weight(\n\u001B[0;32m    103\u001B[0m             name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    104\u001B[0m             shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtype_vocab_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size],\n\u001B[0;32m    105\u001B[0m             initializer\u001B[38;5;241m=\u001B[39mget_initializer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitializer_range),\n\u001B[0;32m    106\u001B[0m         )\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: Exception encountered when calling layer \"roberta\" \"                 f\"(type TFRobertaMainLayer).\n\n{{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50265,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2]\n\nCall arguments received by layer \"roberta\" \"                 f\"(type TFRobertaMainLayer):\n  • input_ids=tf.Tensor(shape=(3, 5), dtype=int32)\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client.session import InteractiveSession\n",
    "from tensorflow.core.protobuf.config_pb2 import GPUOptions, ConfigProto\n",
    "from transformers import pipeline\n",
    "\n",
    "gpu_options = GPUOptions(allow_growth=True)\n",
    "session = InteractiveSession(config=ConfigProto(gpu_options=gpu_options))\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
    "print(sentiment_analysis(\"I love my girl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "gpu2",
   "language": "python",
   "display_name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
